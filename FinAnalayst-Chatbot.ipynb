{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12701853,"sourceType":"datasetVersion","datasetId":8027465}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-07T14:42:41.664649Z","iopub.execute_input":"2025-08-07T14:42:41.664872Z","iopub.status.idle":"2025-08-07T14:42:44.404177Z","shell.execute_reply.started":"2025-08-07T14:42:41.664854Z","shell.execute_reply":"2025-08-07T14:42:44.403442Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/finqa-ds/dev.json\n/kaggle/input/finqa-ds/train.json\n/kaggle/input/finqa-ds/test.json\n/kaggle/input/finqa-ds/private_test.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json\nfrom pathlib import Path\n\ndef convert_finqa(input_path, output_path):\n    with open(input_path, 'r', encoding='utf-8') as f:\n        raw_data = json.load(f)\n\n    converted = []\n    for item in raw_data:\n        # Soru\n        question = item[\"qa\"][\"question\"]\n        answer = item[\"qa\"].get(\"answer\", \"\")\n\n        # Tabloyu string olarak birleştir\n        table = item.get(\"table\", [])\n        table_text = \"\\n\".join([\" | \".join(row) for row in table])\n\n        # Kaydet\n        converted.append({\n            \"context\": table_text,\n            \"question\": question,\n            \"answer\": answer\n        })\n\n    # JSONL olarak kaydet\n    with open(output_path, 'w', encoding='utf-8') as f:\n        for row in converted:\n            f.write(json.dumps(row, ensure_ascii=False) + '\\n')\n\n# Yollar\nbase_path = \"/kaggle/input/finqa-ds\"\nout_path = \"/kaggle/working\"\n\n# Dönüştürme işlemleri\nconvert_finqa(f\"{base_path}/train.json\", f\"{out_path}/train_converted.jsonl\")\nconvert_finqa(f\"{base_path}/dev.json\", f\"{out_path}/dev_converted.jsonl\")\nconvert_finqa(f\"{base_path}/test.json\", f\"{out_path}/test_converted.jsonl\")\n\nprint(\"✔️ Dönüştürme tamamlandı.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T14:42:44.406022Z","iopub.execute_input":"2025-08-07T14:42:44.406366Z","iopub.status.idle":"2025-08-07T14:42:46.537656Z","shell.execute_reply.started":"2025-08-07T14:42:44.406345Z","shell.execute_reply":"2025-08-07T14:42:46.536741Z"}},"outputs":[{"name":"stdout","text":"✔️ Dönüştürme tamamlandı.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\n\ndata_files = {\n    \"train\": \"/kaggle/working/train_converted.jsonl\",\n    \"validation\": \"/kaggle/working/dev_converted.jsonl\"\n}\n\ndataset = load_dataset(\"json\", data_files=data_files)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T14:42:46.538568Z","iopub.execute_input":"2025-08-07T14:42:46.538920Z","iopub.status.idle":"2025-08-07T14:42:48.981449Z","shell.execute_reply.started":"2025-08-07T14:42:46.538900Z","shell.execute_reply":"2025-08-07T14:42:48.980698Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b65e1f4adad0438e929ea952558a6520"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30b1301fec7b4605be4a3b54324cf22e"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nmodel_name = \"google/flan-t5-base\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T14:42:48.982306Z","iopub.execute_input":"2025-08-07T14:42:48.982719Z","iopub.status.idle":"2025-08-07T14:43:32.230638Z","shell.execute_reply.started":"2025-08-07T14:42:48.982699Z","shell.execute_reply":"2025-08-07T14:43:32.229822Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89fdaaf1e4ce4d19ade6fa167cf8866d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b94864955fc247a2b421d11876ed938f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbf04dde04f149c89032da30f6febfdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c46a644510145c98fe58cd338193c1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a0ff874439443e09bc8207abe5ad0ef"}},"metadata":{}},{"name":"stderr","text":"2025-08-07 14:43:11.652068: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754577792.015297      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754577792.115516      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6daa0046d7db43b69a8631ae6365079d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6953ed02b40a4b47b9c6adb16b9ad463"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"max_input_len = 512\nmax_target_len = 64","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T14:43:32.237455Z","iopub.execute_input":"2025-08-07T14:43:32.238102Z","iopub.status.idle":"2025-08-07T14:43:32.264207Z","shell.execute_reply.started":"2025-08-07T14:43:32.238069Z","shell.execute_reply":"2025-08-07T14:43:32.263562Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def preprocess(example):\n    input_text = f\"question: {example['question']} context: {example['context']}\"\n    model_input = tokenizer(\n        input_text,\n        max_length=max_input_len,\n        truncation=True,\n        padding=\"max_length\"\n    )\n    labels = tokenizer(\n        example[\"answer\"],\n        max_length=max_target_len,\n        truncation=True,\n        padding=\"max_length\"\n    )\n    model_input[\"labels\"] = labels[\"input_ids\"]\n    return model_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T14:43:32.231501Z","iopub.execute_input":"2025-08-07T14:43:32.232066Z","iopub.status.idle":"2025-08-07T14:43:32.236569Z","shell.execute_reply.started":"2025-08-07T14:43:32.232045Z","shell.execute_reply":"2025-08-07T14:43:32.235765Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tokenized_dataset = dataset.map(preprocess)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T14:43:32.265922Z","iopub.execute_input":"2025-08-07T14:43:32.266222Z","iopub.status.idle":"2025-08-07T14:43:38.692181Z","shell.execute_reply.started":"2025-08-07T14:43:32.266200Z","shell.execute_reply":"2025-08-07T14:43:38.691538Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6251 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dea3227418414847a75c7bf31eb3d5f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/883 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"972b908a877b41c4be2deca5e01ab83a"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./finqa-trained-model\",         \n    eval_strategy=\"epoch\",             \n    learning_rate=2e-4,                          \n    per_device_train_batch_size=4,              \n    per_device_eval_batch_size=4,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=3,                         \n    predict_with_generate=True,\n    fp16=True,                        \n    logging_dir=\"./logs\",\n    logging_steps=10,  \n    report_to=\"none\",\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T15:18:16.645098Z","iopub.execute_input":"2025-08-07T15:18:16.645910Z","iopub.status.idle":"2025-08-07T15:18:16.679538Z","shell.execute_reply.started":"2025-08-07T15:18:16.645884Z","shell.execute_reply":"2025-08-07T15:18:16.678813Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T15:18:20.606866Z","iopub.execute_input":"2025-08-07T15:18:20.607565Z","iopub.status.idle":"2025-08-07T15:18:20.622487Z","shell.execute_reply.started":"2025-08-07T15:18:20.607538Z","shell.execute_reply":"2025-08-07T15:18:20.621788Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/360543815.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T15:18:22.865500Z","iopub.execute_input":"2025-08-07T15:18:22.865821Z","iopub.status.idle":"2025-08-07T15:58:19.736333Z","shell.execute_reply.started":"2025-08-07T15:18:22.865797Z","shell.execute_reply":"2025-08-07T15:58:19.735746Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2346/2346 39:51, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.129500</td>\n      <td>0.141212</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.137400</td>\n      <td>0.137637</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.127900</td>\n      <td>0.137369</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2346, training_loss=0.26005219856796363, metrics={'train_runtime': 2396.3778, 'train_samples_per_second': 7.826, 'train_steps_per_second': 0.979, 'total_flos': 1.2841254630457344e+16, 'train_loss': 0.26005219856796363, 'epoch': 3.0})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"model_output_path = \"/kaggle/working/finqa-flan-t5-model\"\n\ntokenizer.save_pretrained(model_output_path)\nmodel.save_pretrained(model_output_path)\n\nprint(\"✅ Model ve tokenizer kaydedildi:\", model_output_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T15:59:44.731630Z","iopub.execute_input":"2025-08-07T15:59:44.731923Z","iopub.status.idle":"2025-08-07T15:59:46.355884Z","shell.execute_reply.started":"2025-08-07T15:59:44.731903Z","shell.execute_reply":"2025-08-07T15:59:46.355112Z"}},"outputs":[{"name":"stdout","text":"✅ Model ve tokenizer kaydedildi: /kaggle/working/finqa-flan-t5-model\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}